import itertools
import pandas as pd
import time
import os
import sys
import threading
from datetime import datetime
from autoencoder_newmodule import train_autoencoder

# ì „ì—­ ë½ìœ¼ë¡œ ì¤‘ë³µ ì‹¤í–‰ ë°©ì§€
experiment_lock = threading.Lock()

def main():
    print("ğŸ”¥ ì‹¤í—˜ ì‹œì‘ ì‹œê°„:", datetime.now().strftime("%Y-%m-%d %H:%M:%S"))
    print("="*80)
    
    # runs í´ë” ê²½ë¡œ ì„¤ì • ë° ìƒì„±
    base_runs_path = r"C:\Users\USER\Desktop\FLIGHT_DATA\workspace\autoencoder\newmodel\runs2"
    if not os.path.exists(base_runs_path):
        os.makedirs(base_runs_path)
        print(f"ğŸ“ runs í´ë” ìƒì„±: {base_runs_path}")
    else:
        print(f"ğŸ“ runs í´ë” í™•ì¸: {base_runs_path}")
    
    # ì‹¤í—˜í•  í•˜ì´í¼íŒŒë¼ë¯¸í„° ì¡°í•©ë“¤

    model_types = ["improved", "vae", "beta_vae", "ensemble"]  # ìƒˆë¡œìš´ ëª¨ë¸ íƒ€ì…ë“¤
    batch_sizes = [4, 8, 16, 32, 64,]
    learning_rates = [
            # ë†’ì€ í•™ìŠµë¥  (ë¹ ë¥¸ í•™ìŠµ)
            1e-2, 5e-3, 3e-3, 2e-3, 1e-3,
            # ì¤‘ê°„ í•™ìŠµë¥  (ê· í˜•)
            9e-4, 7e-4, 5e-4, 3e-4, 2e-4, 1e-4,
            # ë‚®ì€ í•™ìŠµë¥  (ì •ë°€í•œ í•™ìŠµ)
            9e-5, 7e-5, 5e-5, 3e-5, 2e-5, 1e-5,
        ]    
    epochs_list = [500]
    
    # ë¡œê·¸ ë³€í™˜ëœ ë°ì´í„° ê²½ë¡œ
    data_path = r"C:\Users\USER\Desktop\FLIGHT_DATA\workspace\autoencoder\59ê°œ59ê°œ ë¹¼ê³  ë‚¨ì€ê±°(í•™ìŠµìš©ë°ì´í„°)(ë¡œê·¸ë³€í™˜).csv"
    
    # ë°ì´í„° íŒŒì¼ ì¡´ì¬ í™•ì¸
    if not os.path.exists(data_path):
        print(f"âŒ ë°ì´í„° íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {data_path}")
        sys.exit(1)
    
    # ê²°ê³¼ ì €ì¥ìš© ë¦¬ìŠ¤íŠ¸ì™€ íŒŒì¼ëª… ì„¤ì • (runs í´ë” ì•ˆì— ì €ì¥)
    results = []
    experiment_start_time = datetime.now().strftime("%Y%m%d_%H%M%S")
    results_filename = os.path.join(base_runs_path, f"experiment_results_{experiment_start_time}.csv")
    
    print(f"ğŸ“ ê²°ê³¼ëŠ” '{results_filename}' íŒŒì¼ì— ì €ì¥ë©ë‹ˆë‹¤.")
    
    # ì „ì²´ ì‹¤í—˜ ê°œìˆ˜ ê³„ì‚°
    total_experiments = len(model_types) * len(batch_sizes) * len(learning_rates) * len(epochs_list)
    print(f"ğŸ“Š ì´ {total_experiments}ê°œì˜ ì‹¤í—˜ì„ ì§„í–‰í•©ë‹ˆë‹¤.")
    print(f"ğŸ¤– Model types: {len(model_types)}ê°œ - {model_types}")
    print(f"ğŸ”¢ Batch sizes: {len(batch_sizes)}ê°œ - {batch_sizes}")
    print(f"ğŸ”¢ Learning rates: {len(learning_rates)}ê°œ - ë²”ìœ„: {min(learning_rates):.0e} ~ {max(learning_rates):.0e}")
    print(f"ğŸ”¢ Epochs: {epochs_list}")
    print(f"â±ï¸ ì˜ˆìƒ ì†Œìš”ì‹œê°„: ì•½ {total_experiments * 4:.0f}ë¶„ ({total_experiments * 4 / 60:.1f}ì‹œê°„)")
    print("="*80)
    
    # í•˜ì´í¼íŒŒë¼ë¯¸í„° ì¡°í•© ë£¨í”„
    experiment_count = 0
    
    for model_type, batch_size, lr, epochs in itertools.product(model_types, batch_sizes, learning_rates, epochs_list):
        experiment_count += 1
        
        print(f"\nğŸš§ ì‹¤í—˜ {experiment_count}/{total_experiments}")
        print(f"ğŸ“ ì„¤ì • - Batch Size: {batch_size}, LR: {lr}, Epochs: {epochs}")
        print("-" * 60)
        
        try:
            start_time = time.time()
            print(f"â° ì‹¤í—˜ {experiment_count} ì‹œì‘ ì‹œê°„: {datetime.now().strftime('%H:%M:%S')}")
            
            # í˜„ì¬ ì‘ì—… ë””ë ‰í† ë¦¬ë¥¼ runs í´ë”ë¡œ ì„ì‹œ ë³€ê²½
            original_cwd = os.getcwd()
            os.chdir(base_runs_path)
            
            try:
                # ì‹¤í—˜ ì‹¤í–‰
                model, scaler, model_path, scaler_path, log_dir = train_autoencoder(
                    data_path=data_path,
                    batch_size=batch_size,
                    epochs=epochs,
                    lr=lr,
                    model_type=model_type
                )
                
                # ìƒëŒ€ ê²½ë¡œë¥¼ ì ˆëŒ€ ê²½ë¡œë¡œ ë³€í™˜
                if model_path and not os.path.isabs(model_path):
                    model_path = os.path.join(base_runs_path, model_path)
                if scaler_path and not os.path.isabs(scaler_path):
                    scaler_path = os.path.join(base_runs_path, scaler_path)
                if log_dir and not os.path.isabs(log_dir):
                    log_dir = os.path.join(base_runs_path, log_dir)
                    
            finally:
                # ì›ë˜ ì‘ì—… ë””ë ‰í† ë¦¬ë¡œ ë³µì›
                os.chdir(original_cwd)
            
            duration = time.time() - start_time
            print(f"â° ì‹¤í—˜ {experiment_count} ì™„ë£Œ ì‹œê°„: {datetime.now().strftime('%H:%M:%S')}")
            
            # ê²°ê³¼ ê¸°ë¡
            results.append({
                "experiment_id": experiment_count,
                "model_type": model_type,
                "batch_size": batch_size,
                "learning_rate": lr,
                "epochs": epochs,
                "model_path": model_path,
                "scaler_path": scaler_path,
                "log_folder": log_dir,
                "train_time_sec": round(duration, 2),
                "status": "completed",
                "timestamp": datetime.now().strftime("%Y-%m-%d %H:%M:%S")
            })
            
            print(f"âœ… ì‹¤í—˜ {experiment_count}/{total_experiments} ì™„ë£Œ!")
            print(f"   ğŸ¤– ëª¨ë¸íƒ€ì…: {model_type}")
            print(f"   ğŸ“Š ë°°ì¹˜í¬ê¸°: {batch_size}, í•™ìŠµë¥ : {lr}")
            print(f"   â±ï¸ ì†Œìš”ì‹œê°„: {duration:.2f}ì´ˆ ({duration/60:.1f}ë¶„)")
            print(f"   ğŸ’¾ ëª¨ë¸ì €ì¥: {model_path}")
            print(f"   ğŸ’¾ ìŠ¤ì¼€ì¼ëŸ¬: {scaler_path}")
            print(f"   ğŸ“Š ë¡œê·¸í´ë”: {log_dir}")
            
            
            # ì‹¤í—˜ ì™„ë£Œ í›„ ì¦‰ì‹œ CSVì— ê¸°ë¡
            results_df = pd.DataFrame(results)
            results_df.to_csv(results_filename, index=False)
            print(f"   ğŸ“ ê²°ê³¼ ì—…ë°ì´íŠ¸: {os.path.basename(results_filename)} (ì´ {len(results)}ê°œ ì‹¤í—˜ ì™„ë£Œ)")
            print("=" * 60)
            
        except Exception as e:
            print(f"âŒ ì‹¤í—˜ {experiment_count} ì‹¤íŒ¨: {str(e)}")
            
            # ì‹¤íŒ¨í•œ ì‹¤í—˜ë„ ê¸°ë¡
            results.append({
                "experiment_id": experiment_count,
                "model_type": model_type,
                "batch_size": batch_size,
                "learning_rate": lr,
                "epochs": epochs,
                "model_path": None,
                "scaler_path": None,
                "log_folder": None,
                "train_time_sec": None,
                "train_time_min": None,
                "status": "failed",
                "error": str(e),
                "timestamp": datetime.now().strftime("%Y-%m-%d %H:%M:%S")
            })
            
            # ì‹¤íŒ¨í•œ ì‹¤í—˜ë„ ì¦‰ì‹œ CSVì— ê¸°ë¡
            results_df = pd.DataFrame(results)
            results_df.to_csv(results_filename, index=False)
            print(f"   ğŸ“ ì‹¤íŒ¨ ê²°ê³¼ë„ ì—…ë°ì´íŠ¸: {os.path.basename(results_filename)}")
            
            # ì—ëŸ¬ ë°œìƒ ì‹œì—ë„ ê³„ì† ì§„í–‰
            continue  # ë‹¤ìŒ ì‹¤í—˜ ê³„ì† ì§„í–‰
    
    # ìµœì¢… ìš”ì•½ ì¶œë ¥
    print("\n" + "="*80)
    print("ğŸ¯ ëª¨ë“  ê°œì„ ëœ ì˜¤í† ì¸ì½”ë” ì‹¤í—˜ ì™„ë£Œ!")
    print(f"ğŸ“Š ì´ {len(results)}ê°œ ì‹¤í—˜ ìˆ˜í–‰")
    print(f"âœ… ì„±ê³µ: {len([r for r in results if r['status'] == 'completed'])}ê°œ")
    print(f"âŒ ì‹¤íŒ¨: {len([r for r in results if r['status'] == 'failed'])}ê°œ")
    print(f"ğŸ’¾ ìµœì¢… ê²°ê³¼: {results_filename}")
    print(f"ğŸ“ ëª¨ë“  íŒŒì¼ ì €ì¥ ìœ„ì¹˜: {base_runs_path}")
    print("="*80)

if __name__ == "__main__":
    # ìŠ¤í¬ë¦½íŠ¸ê°€ ì§ì ‘ ì‹¤í–‰ë  ë•Œë§Œ main í•¨ìˆ˜ í˜¸ì¶œ
    main()